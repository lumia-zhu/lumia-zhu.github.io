<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Sans:300,300italic,400,400italic,700,700italic|JetBrains Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="* indicates Equal Contribution “This is Human Intelligence Debugging Artificial Intelligence”: Examining How People Prompt GPT in Seeking Mental Health SupportInternational Journal of Human-Computer S">
<meta property="og:type" content="website">
<meta property="og:title" content="Research">
<meta property="og:url" content="http://example.com/Research/index.html">
<meta property="og:site_name" content="Zihao ZHU">
<meta property="og:description" content="* indicates Equal Contribution “This is Human Intelligence Debugging Artificial Intelligence”: Examining How People Prompt GPT in Seeking Mental Health SupportInternational Journal of Human-Computer S">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/Research/index/IJHCS_Prompt.png">
<meta property="og:image" content="http://example.com/Research/index/CHI25_Prototype.png">
<meta property="og:image" content="http://example.com/Research/index/ARCam.png">
<meta property="og:image" content="http://example.com/Research/index/GraphMSE.png">
<meta property="og:image" content="http://example.com/Research/index/BiSeNet.png">
<meta property="article:published_time" content="2025-06-13T07:01:22.187Z">
<meta property="article:modified_time" content="2025-06-13T07:01:22.187Z">
<meta property="article:author" content="Zihao ZHU">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/Research/index/IJHCS_Prompt.png">

<link rel="canonical" href="http://example.com/Research/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Research | Zihao ZHU
</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YYYVC589D7"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-YYYVC589D7');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zihao ZHU</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-experience">

    <a href="/Experience" rel="section"><i class="fa  fa-graduation-cap fa-fw"></i>Experience</a>

  </li>
        <li class="menu-item menu-item-research">

    <a href="/Research" rel="section"><i class="fa fa-book fa-fw"></i>Research</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="en">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">Research
</h1>

<div class="post-meta">
  

</div>

</header>

      
      
      
      <div class="post-body">
          <p>* indicates Equal Contribution</p>
<h3 id="“This-is-Human-Intelligence-Debugging-Artificial-Intelligence”-Examining-How-People-Prompt-GPT-in-Seeking-Mental-Health-Support"><a href="#“This-is-Human-Intelligence-Debugging-Artificial-Intelligence”-Examining-How-People-Prompt-GPT-in-Seeking-Mental-Health-Support" class="headerlink" title="“This is Human Intelligence Debugging Artificial Intelligence”: Examining How People Prompt GPT in Seeking Mental Health Support"></a><strong>“This is Human Intelligence Debugging Artificial Intelligence”: Examining How People Prompt GPT in Seeking Mental Health Support</strong></h3><p><em>International Journal of Human-Computer Studies (IJHCS), 2025</em></p>
<img src="/Research/index/IJHCS_Prompt.png" width="80%">

<p><strong>Authors:</strong> Zhuoyang LI*, <strong>Zihao ZHU</strong>*, Xinning Gui, Yuhan LUO</p>
<p><strong>Abstract:</strong> Large language models (LLMs) could extend AI support for mental well-being with their unprecedented language understanding and generation ability. While we have seen individuals who lack access to professional care utilizing LLMs for mental health support, it is unclear how they prompt and interact with LLMs given their individualized emotional needs and life situations. In this work, we analyzed 49 threads and 7,538 comments on Reddit, aiming to understand how people seek mental health support from GPT by creating and crafting various prompts. Despite GPT explicitly disclaiming that it is not an alternative to professional care, we found that users continued to use it for support and devised different prompts to bypass the safety guardrails. Meanwhile, users actively refined and shared their prompts to make GPT more human-like by specifying nuanced communication styles and cultivating in-depth discussions. They also came up with several strategies to make GPT communicate more efficiently to enrich the customized personas on the fly or gain multiple perspectives. Reflecting on these findings, we discuss the tensions associated with using LLMs for mental health support and the implications for designing safer and more empowering human-LLM interactions.</p>
<p><strong>Paper:</strong> <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.ijhcs.2025.103555">Download Paper</a></p>
<hr>
<h3 id="Exploring-LLM-Powered-Role-and-Action-Switching-Pedagogical-Agents-for-History-Education-in-Virtual-Reality"><a href="#Exploring-LLM-Powered-Role-and-Action-Switching-Pedagogical-Agents-for-History-Education-in-Virtual-Reality" class="headerlink" title="Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality"></a><strong>Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality</strong></h3><p><em>ACM Conference on Human Factors in Computing Systems (CHI), 2025</em></p>
<img src="/Research/index/CHI25_Prototype.png" width="80%">

<p><strong>Authors:</strong> <strong>Zihao ZHU</strong>, Ao YU, Xin TONG, Pan HUI</p>
<p><strong>Abstract:</strong> Multi-role pedagogical agents can create engaging and immersive learning experiences, helping learners better understand knowledge in history learning. However, existing pedagogical agents often struggle with multi-role interactions due to complex controls, limited feedback forms, and difficulty dynamically adapting to user inputs. In this study, we developed a VR prototype with LLM-powered adaptive role-switching and action-switching pedagogical agents to help users learn about the history of the Pavilion of Prince Teng. A 2 x 2 between-subjects study was conducted with 84 participants to assess how adaptive role-switching and action-switching affect participants’ learning outcomes and experiences. The results suggest adaptive role-switching enhances participants’ trustworthiness, expertise, and learning motivation but may lead to inconsistent learning experiences. Adaptive action-switching increases participants’ perceived social presence, expertise, learning motivation, and humanness. The study did not uncover any effects of role-switching and action-switching on usability or cognitive load. Based on the findings, we proposed five design implications for integrating adaptive role-switching and action-switching in future VR history education.</p>
<p><strong>Paper:</strong> <a href="index/CHI25_Pedagogical_agent.pdf">Download Paper</a></p>
<hr>
<h3 id="ARCam-A-User-Defined-Camera-for-AR-Photographic-Art-Creation"><a href="#ARCam-A-User-Defined-Camera-for-AR-Photographic-Art-Creation" class="headerlink" title="ARCam: A User-Defined Camera for AR Photographic Art Creation"></a><strong>ARCam: A User-Defined Camera for AR Photographic Art Creation</strong></h3><p><em>IEEE Conference on Virtual Reality and 3D User Interfaces (VR), 2023 Demo</em></p>
<p><img src="/Research/index/ARCam.png"></p>
<p><strong>Authors:</strong> Xinyi LUO, <strong>Zihao ZHU</strong>, Yuyang WANG, Pan HUI</p>
<p><strong>Abstract:</strong> Photography in augmented reality can be challenging due to the restrictions of pre-defined settings. However, adjustable photography settings and real-time previews are significant for AR photographic creation as creators must adjust multiple camera properties to present unique visual effects. In this work, we designed an AR camera (ARCam) with various adjustable properties to give users a high degree of freedom for photographic art creation in real-time preview.</p>
<p><strong>Paper:</strong> <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/10108810">Download Paper</a></p>
<hr>
<h3 id="GraphMSE-Efficient-Meta-path-Selection-in-Semantically-Aligned-Feature-Space-for-Graph-Neural-Networks"><a href="#GraphMSE-Efficient-Meta-path-Selection-in-Semantically-Aligned-Feature-Space-for-Graph-Neural-Networks" class="headerlink" title="GraphMSE: Efficient Meta-path Selection in Semantically Aligned Feature Space for Graph Neural Networks"></a><strong>GraphMSE: Efficient Meta-path Selection in Semantically Aligned Feature Space for Graph Neural Networks</strong></h3><p><em>AAAI Conference on Artificial Intelligence, 2021</em></p>
<p><img src="/Research/index/GraphMSE.png"></p>
<p><strong>Authors:</strong> Yi LI, Yilun JIN, Guojie SONG, <strong>Zihao ZHU</strong>, Chuan SHI, Yiming WANG</p>
<p><strong>Abstract:</strong> Heterogeneous information networks (HINs) are ideal for describing real-world data with different types of entities and relationships. To carry out machine learning on HINs, meta-paths are widely utilized to extract semantics with pre-defined patterns, and models such as graph convolutional networks (GCNs) are thus enabled. However, previous works generally assume a fixed set of meta-paths, which is unrealistic as real-world data are overwhelmingly diverse. Therefore, it is appealing if meta-paths can be automatically selected given an HIN, yet existing works aiming at such problem possess drawbacks, such as poor efficiency and ignoring feature heterogeneity. To address these drawbacks, we propose GraphMSE, an efficient heterogeneous GCN combined with automatic meta-path selection. Specifically, we design highly efficient meta-path sampling techniques, and then injectively project sampled meta-path instances to vectors. We then design a novel semantic feature space alignment, aiming to align the meta-path instance vectors and hence facilitate meta-path selection. Extensive experiments on real-world datasets demonstrate that GraphMSE outperforms state-of-the-art counterparts, figures out important meta-paths, and is dramatically (e.g. 200 times) more efficient.</p>
<p><strong>Paper:</strong> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/download/16544/16351">Download Paper</a></p>
<hr>
<h3 id="Real-Time-Semantic-Segmentation-of-Aerial-Videos-Based-on-Bilateral-Segmentation-Network"><a href="#Real-Time-Semantic-Segmentation-of-Aerial-Videos-Based-on-Bilateral-Segmentation-Network" class="headerlink" title="Real-Time Semantic Segmentation of Aerial Videos Based on Bilateral Segmentation Network"></a><strong>Real-Time Semantic Segmentation of Aerial Videos Based on Bilateral Segmentation Network</strong></h3><p><em>IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2021</em></p>
<p><img src="/Research/index/BiSeNet.png"></p>
<p><strong>Authors:</strong> Yihao ZUO, Junli YANG, <strong>Zihao ZHU</strong>, Ruizhe LI, Yuhan ZHOU, Yutong ZHENG</p>
<p><strong>Abstract:</strong> In recent years, deep learning algorithms have been widely used in semantic segmentation of aerial images. However, most of the current research in this field focus on images but not videos. In this paper, we address the problem of real-time aerial video semantic segmentation with BiSeNet[1]. Since BiSeNet is originally proposed for semantic segmentation of natural city scene images, we need a corresponding dataset to ensure the effect of transfer learning when applying it to aerial video segmentation. Therefore, we build a UAV streetscape sequence dataset (USSD) to fill the vacancy of dataset in this field and facilitate our research. Evaluation on USSD shows that BiSeNet outperforms other state-of-the-art methods. It achieves 79.26% mIoU and 93.37% OA with speed of 148.7 FPS on NVIDIA Tesla V100 for a 1920x1080 frame size input aerial video, which satisfies the demand of aerial video semantic segmentation with a competitive balance of accuracy and speed. The aerial video semantic segmentation results are provided at Our Repository.</p>
<p><strong>Paper:</strong> <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9554952">Download Paper</a></p>

      </div>
      
      
      
    </div>
    

    
    
    


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%9CThis-is-Human-Intelligence-Debugging-Artificial-Intelligence%E2%80%9D-Examining-How-People-Prompt-GPT-in-Seeking-Mental-Health-Support"><span class="nav-number">1.</span> <span class="nav-text">“This is Human Intelligence Debugging Artificial Intelligence”: Examining How People Prompt GPT in Seeking Mental Health Support</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Exploring-LLM-Powered-Role-and-Action-Switching-Pedagogical-Agents-for-History-Education-in-Virtual-Reality"><span class="nav-number">2.</span> <span class="nav-text">Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ARCam-A-User-Defined-Camera-for-AR-Photographic-Art-Creation"><span class="nav-number">3.</span> <span class="nav-text">ARCam: A User-Defined Camera for AR Photographic Art Creation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GraphMSE-Efficient-Meta-path-Selection-in-Semantically-Aligned-Feature-Space-for-Graph-Neural-Networks"><span class="nav-number">4.</span> <span class="nav-text">GraphMSE: Efficient Meta-path Selection in Semantically Aligned Feature Space for Graph Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Real-Time-Semantic-Segmentation-of-Aerial-Videos-Based-on-Bilateral-Segmentation-Network"><span class="nav-number">5.</span> <span class="nav-text">Real-Time Semantic Segmentation of Aerial Videos Based on Bilateral Segmentation Network</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zihao ZHU"
      src="/uploads/avatar.png">
  <p class="site-author-name" itemprop="name">Zihao ZHU</p>
  <div class="site-description" itemprop="description">Empowering us all</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://scholar.google.com/citations?hl=en&user=oMMmYqQAAAAJ" title="Scholar → https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl&#x3D;en&amp;user&#x3D;oMMmYqQAAAAJ" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>Scholar</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/lumia-zhu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lumia-zhu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zihaozhu9-c@my.cityu.edu.hk" title="E-Mail → mailto:zihaozhu9-c@my.cityu.edu.hk" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zihao-zhu-6899a52a5/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zihao-zhu-6899a52a5&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



<div class="recent-news-widget motion-element">
  <div class="recent-news-title">
    <i class="fa fa-newspaper fa-fw"></i>
    Recent News
  </div>
  <ul class="recent-news-list">
    <li class="recent-news-item">
      <span class="news-date">2025.05</span>
      <span class="news-content">One paper accepted to IJHCS</span>
    </li>
    <li class="recent-news-item">
      <span class="news-date">2025.04</span>
      <span class="news-content">Assisted in organizing <a href="https://gbahci.com/prechi2025/" target="_blank">GBA Pre-CHI 2025</a> as student volunteer chair</span>
    </li>
    <li class="recent-news-item">
      <span class="news-date">2025.01</span>
      <span class="news-content">One paper accepted to CHI' 25</span>
    </li>
  </ul>
</div> 
      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zihao ZHU</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
